<!DOCTYPE html>
<html lang="en">
<head>
          <title>How to discover web scraping targets?</title>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pure/1.0.0/pure-min.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pure/1.0.0/grids-responsive-min.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fork-awesome/1.1.7/css/fork-awesome.min.css">
        <link rel="stylesheet" href="http://crawl.blog/theme/css/main.css" />
        <link href="ðŸ•· crawl.blog/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="ðŸ•· crawl.blog Full Atom Feed" />
        <link href="ðŸ•· crawl.blog/atom.xml" type="application/atom+xml" rel="alternate" title="ðŸ•· crawl.blog Atom Feed" />
        <link href="ðŸ•· crawl.blog/rss.xml" type="application/rss+xml" rel="alternate" title="ðŸ•· crawl.blog RSS Feed" />
        <link href="ðŸ•· crawl.blog/feeds/{slug}.atom.xml" type="application/atom+xml" rel="alternate" title="ðŸ•· crawl.blog Categories Atom Feed" />

  <meta name="author" content="granitosaurus"/>
  <meta name="description" content="Finding all scrape targets can be a difficult and tedious process. In this post we&#39;ll cover main target (e.g. product) discovery techniques. In other words: how do you find all of the products on the website?"/>
<meta property="og:site_name" content="ðŸ•· crawl.blog"/>
<meta property="og:title" content="How to discover web scraping targets?"/>
<meta property="og:description" content="Finding all scrape targets can be a difficult and tedious process. In this post we&#39;ll cover main target (e.g. product) discovery techniques. In other words: how do you find all of the products on the website?"/>
<meta property="og:locale" content="en_US"/>
<meta property="og:url" content="http://crawl.blog/drafts/discovery-p1.html"/>
<meta property="og:type" content="article"/>
<meta property="article:published_time" content="2020-05-16 00:00:00+02:00"/>
<meta property="article:modified_time" content=""/>
<meta property="article:author" content="http://crawl.blog/author/granitosaurus.html">
<meta property="article:section" content="guides"/>
<meta property="article:tag" content="techniques"/>
<meta property="og:image" content="">
        <link rel="stylesheet" href="http://crawl.blog/theme/css/applause-button.css" />
          <script src="http://crawl.blog/theme/js/applause-button.js"></script>
</head>
<body>

    <div class="navigation pure-menu pure-menu-horizontal pure-menu-scrollable">
        <a href="http://crawl.blog/" class="pure-menu-heading  pure-menu-link">ðŸ•· crawl.blog</a>
        <ul class="pure-menu-list">
            <li class="pure-menu-item"></li>
              <li class="pure-menu-item"><a href="http://crawl.blog/pages/about.html" class="pure-menu-link">about</a></li>
              <li class="pure-menu-item"><a href="http://crawl.blog/category/guides.html" class="pure-menu-link">guides</a></li>
              <li class="pure-menu-item"><a href="http://crawl.blog/category/research.html" class="pure-menu-link">research</a></li>
              <li class="pure-menu-item"><a href="http://crawl.blog/category/tools.html" class="pure-menu-link">tools</a></li>
              <li class="pure-menu-item pure-menu-selected">
                <a href="atom.xml" class="pure-menu-link">
                  <i class="fa fa-rss" aria-hidden="true"></i>
                </a>
              </li>
        </ul>
    </div>
  <div class="page-container">
  <div class="entry-content">
    <div class="post-meta pure-g">

<div class="pure-u-3-4 meta-data">
    <a href="http://crawl.blog/category/guides.html" class="category">guides</a>
    &mdash; <span title="2020-05-16T00:00:00+02:00">Sat 16 May 2020</span></br>
    <a href="http://crawl.blog/tag/techniques" class="tag">techniques</a>
    </br>
</div>    </div>
  </div>

  <div class="article-header-container">
    <div class="background-image-container title">

        <div class="background-image-small">
          <div class="title-container">
            <h1>How to discover web scraping targets?</h1>
          </div>
        </div>
    </div>
    <div class="entry-content article">
      <!--insert table of contents between text and first header-->
      <p>Finding all scrape targets can be a difficult and tedious process. In this post we'll cover main target (e.g. product) discovery techniques. In other words: how do you find all of the products on the website?</p>
<p>Let's imagine a web-scraping scenario: you want to scrape all products on an e-commerce website. Well first we need to find urls to the product pages themselves, let's see what are the ways to do that.</p>

      <h2>Deep Crawling - The Hammer Approach</h2>
<p>First obvious method would be just to start a crawler on homepage and crawl all of the links on the front page, then crawl all of the links on those pages and keep digging deeper and deeper.  </p>
<p>On paper this sounds like a great approach to find all of the products but in reality this is an extremely inefficient method as you'll end up crawling all of the web pages instead of only what you want.  </p>
<p>Furthermore this doesn't guarantee full coverage either:
* Links can be javascript generated - meaning without executing javascript our crawler will not find any product links.<br>
* Links can simply be not present because the website might not want users finding them. e.g. old clothes collection should not steal the thunder from the new collection.
* Your crawler might fail to handle some edge cases like malformed or corrupted links.</p>
<p>Finally there's resource issues:
* If websites have rate limits you'll reach them quicker and burn through proxies unnecessarily. 
* More crawling means more resources wasted by your and by your target website.</p>
<p>Needless to say this method has much more negatives than positives. That being said it might be the only option when broad crawling unknown targets.</p>
<h2>Robots.txt and Sitemaps</h2>
<p>Fortunately for us, most websites want to be crawled by search engines and such. Websites often have <code>robots.txt</code> file which instructs crawlers on crawling rules â€” what parts of website should be crawled and what parts shouldn't be. We can use robots.txt to discover general site's structure, maybe there's a product page directory or some interesting endpoint?</p>
<p>The most important thing often found in robots txt is <code>sitemap</code> document, often called <code>sitemap.xml</code>. This document contains direct links to products themselves:</p>
<div class="highlight"><pre><span></span>Sitemap: https://www.nytimes.com/sitemaps/new/news.xml.gz
Sitemap: https://www.nytimes.com/sitemaps/new/sitemap.xml.gz
Sitemap: https://www.nytimes.com/sitemaps/new/wire.xml.gz
Sitemap: https://www.nytimes.com/sitemaps/new/collections.xml.gz
Sitemap: https://www.nytimes.com/sitemaps/new/video.xml.gz
Sitemap: https://www.nytimes.com/sitemaps/new/cooking.xml.gz
Sitemap: https://www.nytimes.com/sitemaps/www.nytimes.com/2016_election_sitemap.xml.gz
Sitemap: https://www.nytimes.com/elections/2018/sitemap
</pre></div>


<p>Here's an example of nytimes.com/robots.txt containing all of the sitemap links!</p>
<p>However if neither sitemap or directory is present we can still can find useful information in <code>robots.txt</code> rule set, such as search endpoints, category directories. In other words by knowing the structure of the website we can find ways to discover products:</p>
<div class="highlight"><pre><span></span>TODO find example
</pre></div>


<p>Explain example here</p>
<h2>Search Field</h2>
    </div>
    <div class="entry-content footer">
      <hr>
      <div class="pure-g">
          <div class="pure-u-1-2">
            <applause-button style="width: 58px; height: 58px;"/>
          </div>
          <div class="tags pure-u-1-2">
              <a href="http://crawl.blog/tag/techniques.html">techniques</a>
          </div>
      </div>
        <script src="https://utteranc.es/client.js"
                repo="crawl-blog/crawl-blog.github.io"
                issue-term="discovery-p1"
                label="comments"
                theme="github-light"
                crossorigin="anonymous"
                async>
        </script>

    </div>
  </div>



    <footer class="index-footer">

        <a href="http://crawl.blog/" title="ðŸ•· crawl.blog">ðŸ•· crawl.blog</a>
        <a href="/archives.html">Archives</a></li>
        <a href="/categories.html">Categories</a></li>
        <a href="/tags.html">Tags</a></li>
        <a href="http://crawl.blog/category/guides.html">guides</a>
        <a href="http://crawl.blog/category/research.html">research</a>
        <a href="http://crawl.blog/category/tools.html">tools</a>
        <a href="atom.xml">
          <i class="fa fa-rss-square" aria-hidden="true"></i>
        </a>

    </footer>

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-132141387-1', 'auto');
      ga('send', 'pageview');

    </script>
</body>
</html>