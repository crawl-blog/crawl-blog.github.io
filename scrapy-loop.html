<!DOCTYPE html>
<html lang="en">
<head>
          <title>Scrapy: How to loop a crawler</title>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pure/1.0.0/pure-min.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pure/1.0.0/grids-responsive-min.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fork-awesome/1.1.7/css/fork-awesome.min.css">
        <link rel="stylesheet" href="/theme/css/main.css" />
        <link href="游동 crawl.blog/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="游동 crawl.blog Full Atom Feed" />
        <link href="游동 crawl.blog/atom.xml" type="application/atom+xml" rel="alternate" title="游동 crawl.blog Atom Feed" />
        <link href="游동 crawl.blog/rss.xml" type="application/rss+xml" rel="alternate" title="游동 crawl.blog RSS Feed" />
        <link href="游동 crawl.blog/feeds/{slug}.atom.xml" type="application/atom+xml" rel="alternate" title="游동 crawl.blog Categories Atom Feed" />

  <meta name="author" content="granitosaurus"/>
  <meta name="description" content="Explore ways to properly loop scrapy crawlers with twisted callbacks."/>
<meta property="og:site_name" content="游동 crawl.blog"/>
<meta property="og:title" content="Scrapy: How to loop a crawler"/>
<meta property="og:description" content="Explore ways to properly loop scrapy crawlers with twisted callbacks."/>
<meta property="og:locale" content="en_US"/>
<meta property="og:url" content="/scrapy-loop.html"/>
<meta property="og:type" content="article"/>
<meta property="article:published_time" content="2019-03-28 00:00:00+01:00"/>
<meta property="article:modified_time" content=""/>
<meta property="article:author" content="/author/granitosaurus.html">
<meta property="article:section" content="guides"/>
<meta property="article:tag" content="scrapy"/>
<meta property="article:tag" content="python"/>
<meta property="og:image" content="">
        <link rel="stylesheet" href="/theme/css/applause-button.css" />
          <script src="/theme/js/applause-button.js"></script>
</head>
<body>

    <div class="navigation pure-menu pure-menu-horizontal pure-menu-scrollable">
        <a href="/" class="pure-menu-heading  pure-menu-link">游동 crawl.blog</a>
        <ul class="pure-menu-list">
            <li class="pure-menu-item"></li>
              <li class="pure-menu-item"><a href="/pages/about.html" class="pure-menu-link">about</a></li>
              <li class="pure-menu-item"><a href="/category/guides.html" class="pure-menu-link">guides</a></li>
              <li class="pure-menu-item"><a href="/category/research.html" class="pure-menu-link">research</a></li>
              <li class="pure-menu-item"><a href="/category/tools.html" class="pure-menu-link">tools</a></li>
              <li class="pure-menu-item pure-menu-selected">
                <a href="atom.xml" class="pure-menu-link">
                  <i class="fa fa-rss" aria-hidden="true"></i>
                </a>
              </li>
        </ul>
    </div>
  <div class="page-container">
  <div class="entry-content">
    <div class="post-meta pure-g">

<div class="pure-u-3-4 meta-data">
    <a href="/category/guides.html" class="category">guides</a>
    &mdash; <span title="2019-03-28T00:00:00+01:00">Thu 28 March 2019</span></br>
    <a href="/tag/scrapy" class="tag">scrapy</a>
    <a href="/tag/python" class="tag">python</a>
    </br>
</div>    </div>
  </div>

  <div class="article-header-container">
    <div class="background-image-container title">

        <div class="background-image-small">
          <div class="title-container">
            <h1>Scrapy: How to loop a crawler</h1>
          </div>
        </div>
    </div>
    <div class="entry-content article">
      <!--insert table of contents between text and first header-->
      <p>Running scrapy crawlers from a script is not difficult, however things start to get more complicated once additional logic needs to be injected. Like if you want to run crawler in an endless loop!</p>
<p><a href="/img/ouroboros.gif"><img src="/img/ouroboros.gif" title=""></img></a><figcaption></figcaption></p>
<p>There are a lot of ways to do this but by since scrapy is using Twisted for crawl loop you can extend the same loop with your on callbacks and errorbacks.
This is how you run scrapy with a script:</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">scrapy</span>
<span class="kn">from</span> <span class="nn">scrapy.crawler</span> <span class="kn">import</span> <span class="n">CrawlerProcess</span>
<span class="kn">from</span> <span class="nn">scrapy.utils.project</span> <span class="kn">import</span> <span class="n">get_project_settings</span>

<span class="k">class</span> <span class="nc">MySpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="c1"># Your spider definition</span>
    <span class="o">...</span>

<span class="n">process</span> <span class="o">=</span> <span class="n">CrawlerProcess</span><span class="p">(</span><span class="n">get_project_settings</span><span class="p">())</span>

<span class="n">process</span><span class="o">.</span><span class="n">crawl</span><span class="p">(</span><span class="n">MySpider</span><span class="p">)</span>
<span class="n">process</span><span class="o">.</span><span class="n">start</span><span class="p">()</span> <span class="c1"># the script will block here until the crawling is finished</span>
</pre></div>


<p>The interesting bit here is that <code>process.crawl(MySpider)</code> actually returns twisted's deferred! We can attach some callbacks to this deferred that will be fired once the crawl finished.
In other words if we want to have an endless loop we can just add a recursive callback - once crawl finishes, crawl again!</p>
<div class="highlight"><pre><span></span><span class="k">proc</span><span class="nb">es</span><span class="nv">s</span> <span class="o">=</span> <span class="nv">CrawlerProcess</span><span class="p">(</span><span class="nv">get_project_settings</span><span class="p">())</span>

<span class="nf">def</span> <span class="nv">_crawl</span><span class="p">(</span><span class="nv">result</span><span class="p">,</span> <span class="nb">sp</span><span class="nv">ider</span><span class="p">):</span>
    <span class="nf">deferred</span> <span class="o">=</span> <span class="nv">process.crawl</span><span class="p">(</span><span class="nb">sp</span><span class="nv">ider</span><span class="p">)</span>
    <span class="nf">deferred.addCallback</span><span class="p">(</span><span class="nv">_crawl</span><span class="p">,</span> <span class="nb">sp</span><span class="nv">ider</span><span class="p">)</span>
    <span class="nf">return</span> <span class="nv">deferred</span>

<span class="nf">_crawl</span><span class="p">(</span><span class="nv">None</span><span class="p">,</span> <span class="nv">Myspider</span><span class="p">)</span>
<span class="k">proc</span><span class="nb">es</span><span class="nv">s.start</span><span class="p">()</span>
</pre></div>


<p>Now once crawl finished another will start immediately!</p>

      <h3>Improvements</h3>
<p>We can still improve on this. First we can <strong>add a sleep</strong> between calls for cases where we want to run crawler only so often.</p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">twisted.internet</span> <span class="kn">import</span> <span class="n">reactor</span>
<span class="kn">from</span> <span class="nn">twisted.internet.task</span> <span class="kn">import</span> <span class="n">deferLater</span>


<span class="k">def</span> <span class="nf">sleep</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="n">seconds</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Non blocking sleep callback&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">deferLater</span><span class="p">(</span><span class="n">reactor</span><span class="p">,</span> <span class="n">seconds</span><span class="p">,</span> <span class="k">lambda</span><span class="p">:</span> <span class="bp">None</span><span class="p">)</span>


<span class="n">process</span> <span class="o">=</span> <span class="n">CrawlerProcess</span><span class="p">(</span><span class="n">get_project_settings</span><span class="p">())</span>


<span class="k">def</span> <span class="nf">_crawl</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="n">spider</span><span class="p">):</span>
    <span class="n">deferred</span> <span class="o">=</span> <span class="n">process</span><span class="o">.</span><span class="n">crawl</span><span class="p">(</span><span class="n">spider</span><span class="p">)</span>
    <span class="n">deferred</span><span class="o">.</span><span class="n">addCallback</span><span class="p">(</span><span class="k">lambda</span> <span class="n">results</span><span class="p">:</span> <span class="k">print</span><span class="p">(</span><span class="s1">&#39;waiting 100 seconds before restart...&#39;</span><span class="p">))</span>
    <span class="n">deferred</span><span class="o">.</span><span class="n">addCallback</span><span class="p">(</span><span class="n">sleep</span><span class="p">,</span> <span class="n">seconds</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
    <span class="n">deferred</span><span class="o">.</span><span class="n">addCallback</span><span class="p">(</span><span class="n">_crawl</span><span class="p">,</span> <span class="n">spider</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">deferred</span>


<span class="n">_crawl</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="n">MySpider</span><span class="p">)</span>
<span class="n">process</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
</pre></div>


<p>Finally we should <strong>handle crashes</strong>. For this we can use errorbacks which will be called if an unhandled exception happens:</p>
<div class="highlight"><pre><span></span><span class="n">def</span> <span class="n">crash</span><span class="p">(</span><span class="n">failure</span><span class="p">):</span>
    <span class="n">print</span><span class="p">(</span><span class="s1">&#39;oops, spider crashed&#39;</span><span class="p">)</span>
    <span class="n">print</span><span class="p">(</span><span class="n">failure</span><span class="p">.</span><span class="n">getTraceback</span><span class="p">())</span>

<span class="n">def</span> <span class="n">_crawl</span><span class="p">(</span><span class="k">result</span><span class="p">,</span> <span class="n">spider</span><span class="p">):</span>
    <span class="k">deferred</span> <span class="o">=</span> <span class="n">process</span><span class="p">.</span><span class="n">crawl</span><span class="p">(</span><span class="n">spider</span><span class="p">)</span>
    <span class="k">deferred</span><span class="p">.</span><span class="n">addCallback</span><span class="p">(</span><span class="n">lambda</span> <span class="n">results</span><span class="p">:</span> <span class="n">print</span><span class="p">(</span><span class="s1">&#39;waiting 100 seconds before restart...&#39;</span><span class="p">))</span>
    <span class="k">deferred</span><span class="p">.</span><span class="n">addErrback</span><span class="p">(</span><span class="n">crash</span><span class="p">)</span>  <span class="o">#</span> <span class="o">&lt;</span><span class="c1">-- add errback here</span>
    <span class="k">deferred</span><span class="p">.</span><span class="n">addCallback</span><span class="p">(</span><span class="n">sleep</span><span class="p">,</span> <span class="n">seconds</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
    <span class="k">deferred</span><span class="p">.</span><span class="n">addCallback</span><span class="p">(</span><span class="n">_crawl</span><span class="p">,</span> <span class="n">spider</span><span class="p">)</span>
    <span class="k">return</span> <span class="k">deferred</span>
</pre></div>


<p>Here if crawler crashes we'll print a message and close the process.</p>
<h3>More Ideas</h3>
<p>You can add as many <code>Errbacks</code> and <code>Callbacks</code> as you want and you can get quite creative with this approach. Send a slack message, check crawler stats, maybe even chain multiple different crawlers!</p>
<h3>Full Implementations</h3>
<p>I wrote a small example with full capabilities like logging, configured intervals and hooks that I used in production with great success.<br>
Check out <a href="https://gitlab.com/granitosaurus/scrapy-loop">scrapy-loop on gitlab</a></p>
<hr>
<h5>Attributions</h5>
<p>The beautiful ouroboros gif is provided by <a href="http://akhildakinedi.com/">Akhil Dakinedi</a></p>
    </div>
    <div class="entry-content footer">
      <hr>
      <div class="pure-g">
          <div class="pure-u-1-2">
            <applause-button style="width: 58px; height: 58px;"/>
          </div>
          <div class="tags pure-u-1-2">
              <a href="/tag/scrapy.html">scrapy</a>
              <a href="/tag/python.html">python</a>
          </div>
      </div>
        <script src="https://utteranc.es/client.js"
                repo="crawl-blog/crawl-blog.github.io"
                issue-term="scrapy-loop"
                label="comments"
                theme="github-light"
                crossorigin="anonymous"
                async>
        </script>

    </div>
  </div>



    <footer class="index-footer">

        <a href="/" title="游동 crawl.blog">游동 crawl.blog</a>
        <a href="/archives.html">Archives</a></li>
        <a href="/categories.html">Categories</a></li>
        <a href="/tags.html">Tags</a></li>
        <a href="/category/guides.html">guides</a>
        <a href="/category/research.html">research</a>
        <a href="/category/tools.html">tools</a>
        <a href="atom.xml">
          <i class="fa fa-rss-square" aria-hidden="true"></i>
        </a>

    </footer>

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-132141387-1', 'auto');
      ga('send', 'pageview');

    </script>
</body>
</html>